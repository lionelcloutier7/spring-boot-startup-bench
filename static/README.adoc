[.lead]
In this module we study the effect of Spring and Spring Boot on startup time by first stripping out as much of it as we can, and then piling on more features, adding more dependencies and letting Spring Boot figure out the desired configuration. In the table below, the "demo" sample is the canonical, empty Spring Boot web app. All the smaller and faster apps are stripped down versions of that where we remove various things and finally get rid of even using reflection in the `BeanFactory` (using the new "functional bean registration").

Results:

* With a couple of outliers we discuss below, the startup time is directly proportional to the number of classes loaded. This usually correlates with the number of beans in the application context, but things like Hibernate and Zuul add more classes than beans.

* Reflection is not a bottleneck - more work would have to be done with more complex scenarios, but the sample that uses functional bean registration for everything fits the curve of the more heavyweight applications, so it isn't intrinsically much faster, it just has fewer beans (and therefore fewer features).

* Condition processing in Spring Boot is not expensive - when we remove conditions partially ("slim", "thin") and completely ("lite", "func") the startup time is right on the curve.

* There is some evidence that most of the cost is associated with JVM overheads, loading and parsing classes (this is supported by other data, for instance on devtools restarts, which are *much* quicker than cold starts).

Since more beans mean more features, you are paying at startup for actual functionality, so in some ways it should be an acceptable cost. On the other hand, there might be features that you end up never using, or don't use until later and you would be willing to defer the cost. Spring doesn't allow you to do that easily. It has some features that might defer the cost of creating beans, but that might not even help if the bean definitions still have to be created and most of the cost is actually to do with loading and parsing classes.

```
Benchmark           Mode  Cnt  Score   Error  Units Beans Classes
DemoBenchmark.zuul  avgt   10  4.510 ± 0.095   s/op 516   9656
DemoBenchmark.erkb  avgt   10  3.137 ± 0.049   s/op 494   7654
DemoBenchmark.busr  avgt   10  2.525 ± 0.038   s/op 392   7129
DemoBenchmark.erko  avgt   10  2.237 ± 0.071   s/op 313   6392
DemoBenchmark.jpaa  avgt   10  3.232 ± 0.057   s/op 257   8297
DemoBenchmark.jpag  avgt   10  2.897 ± 0.023   s/op 178   8294
DemoBenchmark.jpaf  avgt   10  2.865 ± 0.043   s/op 177   8291
DemoBenchmark.jpae  avgt   10  2.829 ± 0.038   s/op 176   8284
DemoBenchmark.jpad  avgt   10  2.739 ± 0.073   s/op 175   7946
DemoBenchmark.conf  avgt   10  1.636 ± 0.029   s/op 250   6232
DemoBenchmark.acjd  avgt   10  1.540 ± 0.049   s/op 226   6033
DemoBenchmark.actr  avgt   10  1.316 ± 0.060   s/op 186   5666
DemoBenchmark.jdbc  avgt   10  1.237 ± 0.050   s/op 147   5625
DemoBenchmark.demo  avgt   10  1.056 ± 0.040   s/op 111   5266
DemoBenchmark.slim  avgt   10  1.003 ± 0.011   s/op 105   5208
DemoBenchmark.thin  avgt   10  0.855 ± 0.028   s/op 60    4892
DemoBenchmark.lite  avgt   10  0.694 ± 0.015   s/op 30    4580
DemoBenchmark.func  avgt   10  0.652 ± 0.017   s/op 25    4378
```

.Number of Classes vs. Startup Time
image::https://docs.google.com/spreadsheets/d/e/2PACX-1vR8B4l5WkWf-9gZWmIYTkmBWM7YWf5bRg852OakrV0G2-vtfM_UkVNRC3cTVk1079HagnMVHYZnvbib/pubchart?oid=88442446&amp;format=image[]

{empty} +

.Number of Beans vs. Startup Time
image::https://docs.google.com/spreadsheets/d/e/2PACX-1vR8B4l5WkWf-9gZWmIYTkmBWM7YWf5bRg852OakrV0G2-vtfM_UkVNRC3cTVk1079HagnMVHYZnvbib/pubchart?oid=2090464856&format=image[]

{empty} +

Legend:

* Zuul: same as "busr" sample but with Zuul proxy
* Jpad: same as "demo" sample but with 1 JPA entity (and 0 repositories)
* Jpae: same as "demo" sample but with 1 JPA entity (and 1 repository)
* Jpaf: same as "demo" sample but with 2 JPA entities (and 2 repositories)
* Jpag: same as "demo" sample but with 3 JPA entities (and 3 repositories)
* Jpaa: same as "actr" sample but with 3 JPA entities (and 3 repositories)
* Erkb: same as "busr" sample but with Eureka client
* Busr: same as "conf" but adds Spring Cloud Bus and Rabbit
* Erko: same as "actr" sample but with Eureka client (disabled)
* Conf: same as "actr" sample plus config client
* Acjd: same as "actr" sample plus JDBC
* Actr: same as "demo" sample plus Actuator
* Jdbc: same as "demo" sample plus JDBC
* Demo: vanilla Spring Boot MVC app with one endpoint (no Actuator)
* Slim: same thing but explicitly `@Imports` all configuration
* Thin: reduce the `@Imports` down to a set of 4 that are needed for the endpoint
* Lite: copy the imports from "thin" and make them into hard-coded, unconditional configuration
* Func: extract the configuration methods from "lite" and register bits of it using the function bean API

N.B. The "thin" sample has `@EnableWebMvc` (implicitly), but "lite"
and "func" pulled the relevant features of that out into a separate
class (so a few beans were dropped).

== Outliers

Only 2 samples didn't fit the trend for classes vs. startup. One starts up slower (Sleuth) and one faster (Erka). The JPA and Zuul samples are outliers for the beans vs. startup correlation, so we include those here again.

```
Benchmark           Mode  Cnt  Score   Error  Units Beans Trend Delta Classes
DemoBenchmark.slth  avgt   10  5.110 ± 0.065   s/op 453    2762  2403    7674
DemoBenchmark.erka  avgt   10  2.183 ± 0.076   s/op 287    2760  -577    7893
DemoBenchmark.jpad  avgt   10  2.739 ± 0.073   s/op 175    1385  1354    7946
DemoBenchmark.jpae  avgt   10  2.829 ± 0.038   s/op 176    1390  1439    8284
DemoBenchmark.jpaf  avgt   10  2.865 ± 0.043   s/op 177    1396  1469    8291
DemoBenchmark.jpag  avgt   10  2.897 ± 0.023   s/op 178    1401  1496    8294
DemoBenchmark.jpaa  avgt   10  3.232 ± 0.057   s/op 257    1814  1418    8297
DemoBenchmark.zuul  avgt   10  4.510 ± 0.095   s/op 516    3080  1430    9596
```

{empty} +

Legend:

* Slth: same as "busr" sample but with Sleuth
* Erka: same as "actr" sample but with Eureka client

The "Trend" number is the best fit prediction of the startup time from the number of classes (or beans for the JPA samples), taken from the non-outlier data. "Delta" is the difference between the actual startup time and the trend value (so it is the extra cost of the features being added).

=== Eureka

The "erka" sample started up _faster_ then predicted, but it also has a suspiciously large number of loaded classes (even more classes than with Eureka and Bus). The loaded classes mesaurements are not stable - you get different answers from run to run - but they don't usually fluctuate by enough to explain the difference here.

=== Sleuth

Here's an explanation for the "slth" result. Spring processes `@annotation` matchers in `@Pointcuts` extremely inefficiently, so the startup time scales with the number of pointcuts with `@annotations`, not so much the number of beans. If the pointcuts are driving it (as suggested by results in these https://github.com/dsyer/spring-boot-aspectj/tree/master/benchmarks[aspectj benchmarks]), then the 4 pointcuts with `@annotation` matchers would be costing 2403ms or around 600ms each, which is horrendous but consistent with the aspectj benchmarks.

=== JPA

Hibernate fixed startup cost is about 1300ms (the "delta" on "jpad"), which more or less doubles the startup time for a JPA app compared to the vanilla "demo". Spring Data JPA repository creation seems to have a fixed cost of about 90ms, which isn't nothing but isn't very large in comparison. Adding repositories and entities might cost something, but it isn't a lot - the best estimate would be about 30ms per entity from these data (these were very basic, vanilla `JpaRepositories`, so maybe it would be more for more complex requirements). The JPA samples (and even Zuul) are a pretty good fit for number of classes loaded versus startup time, so Hibernate isn't doing a lot of intensive stuff beyond forcing a lot of classes to be loaded.

== Running the Benchmarks

```
$ ../mvnw clean install
$ java -jar target/benchmarks.jar
```

There are 2 groups of benchmarks:

1. `SampleBenchmarks` - add features to the "main" demo by manipulating the classpath
2. `SlimBenchmarks` - "slim", "thin", "lite", "func" - stripping away from the "main" demo by hardcoding config

The JMH benchmarks in `SlimBenchmarks` have the same name as the sample, so they can be run individually as

```
$ java -jar target/benchmarks.jar func
```

or altogether as 

```
$ java -jar target/benchmarks.jar SlimBenchmarks
```

The JMH benchmarks in `SampleBenchmarks` are all called "main" but
they have a `@Param` called "sample" whose value is the name of the
sample. They can be run individually or as a group using a
comma-separated list of sample names:

```
$ java -jar target/benchmarks.jar main -P sample=empt,demo
```

or altogether as 

```
$ java -jar target/benchmarks.jar SampleBenchmarks
```

== Old Data

(Boot 1.5.4 without `-noverify`)

|===
| sample | configs | beans | startup(millis)

| slth | 176| 460 | 5366
| zuul | 181| 495 | 4336
| busr | 151| 389 | 2758
| erka | 127| 310 | 2423
| conf | 100| 245 | 1779
| actr | 72 | 183 | 1430
| demo | 32 | 108 | 1154
| slim | 31 | 103 | 1112
| thin | 14 | 60  | 968
| lite | 4  | 30  | 813
| func | 1  | 25  | 742

|===

== Laptop (carbon)

```
Benchmark           Mode  Cnt  Score   Error  Units
DemoBenchmark.demo  avgt   10  1.697 ± 0.081   s/op
DemoBenchmark.slim  avgt   10  1.673 ± 0.098   s/op
DemoBenchmark.thin  avgt   10  1.446 ± 0.061   s/op
DemoBenchmark.lite  avgt   10  1.203 ± 0.072   s/op
DemoBenchmark.func  avgt   10  1.150 ± 0.056   s/op
```